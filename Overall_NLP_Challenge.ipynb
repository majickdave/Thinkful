{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview\n",
    "I will be using two Chesterton texts, Father Brown and The Man Who Was Thursday, along with two Austen texts, Emma and Persuasion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "#Search Gutenberg Corpus and find texts\n",
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning, Processing and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the raw text\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "brown = gutenberg.raw('chesterton-brown.txt')\n",
    "thursday = gutenberg.raw('chesterton-thursday.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Inspect raw files first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died t\n",
      "\n",
      "\n",
      " END\n",
      "[Persuasion by Jane Austen 1818]\n",
      "\n",
      "\n",
      "Chapter 1\n",
      "\n",
      "\n",
      "Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who,\n",
      "for his own amusement, never took up any book but the Baronetage;\n",
      "there he found occupation for an idle hour, and consolation in a\n",
      "distressed one; there his faculties were roused into admiration and\n",
      "respect, by contemplating the limited remnant of the earliest patents;\n",
      "there any unwelcome sensations, arising from domestic affairs\n",
      "changed naturally into pity and contempt as he turn\n",
      "\n",
      "\n",
      " END\n",
      "[The Wisdom of Father Brown by G. K. Chesterton 1914]\n",
      "\n",
      "\n",
      "I. The Absence of Mr Glass\n",
      "\n",
      "\n",
      "THE consulting-rooms of Dr Orion Hood, the eminent criminologist\n",
      "and specialist in certain moral disorders, lay along the sea-front\n",
      "at Scarborough, in a series of very large and well-lighted french windows,\n",
      "which showed the North Sea like one endless outer wall of blue-green marble.\n",
      "In such a place the sea had something of the monotony of a blue-green dado:\n",
      "for the chambers themselves were ruled throughout by a \n",
      "\n",
      "\n",
      " END\n",
      "[The Man Who Was Thursday by G. K. Chesterton 1908]\n",
      "\n",
      "To Edmund Clerihew Bentley\n",
      "\n",
      "A cloud was on the mind of men, and wailing went the weather,\n",
      "Yea, a sick cloud upon the soul when we were boys together.\n",
      "Science announced nonentity and art admired decay;\n",
      "The world was old and ended: but you and I were gay;\n",
      "Round us in antic order their crippled vices came--\n",
      "Lust that had lost its laughter, fear that had lost its shame.\n",
      "Like the white lock of Whistler, that lit our aimless gloom,\n",
      "Men showed their \n"
     ]
    }
   ],
   "source": [
    "#Print first 500 characters of each, followed by 'END'\n",
    "print(emma[0:500])\n",
    "print('\\n\\n END')\n",
    "\n",
    "print(persuasion[0:500])\n",
    "print('\\n\\n END')\n",
    "\n",
    "print(brown[0:500])\n",
    "print('\\n\\n END')\n",
    "\n",
    "print(thursday[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Clean and Process the Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = re.sub(\"\\d+\", \"\", text)\n",
    "    text = re.sub(r'Chapter \\d+', '', text)\n",
    "    text = re.sub(r'VOLUME \\w+', '', text)\n",
    "    text = re.sub(r'CHAPTER \\w+', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run text cleaning utility on our texts\n",
    "emma = text_cleaner(emma)\n",
    "persuasion = text_cleaner(persuasion)\n",
    "brown = text_cleaner(brown)\n",
    "thursday = text_cleaner(thursday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Parse the Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parse the cleaned texts\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "emma_doc = nlp(emma)\n",
    "persuasion_doc = nlp(persuasion)\n",
    "brown_doc = nlp(brown)\n",
    "thursday_doc = nlp(thursday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8905\n",
      "3656\n",
      "3716\n",
      "3490\n"
     ]
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "emma_sents = [[sent, \"Austen\"] for sent in emma_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "brown_sents = [[sent, \"Chesterton\"] for sent in brown_doc.sents]\n",
    "thursday_sents = [[sent, \"Chesterton\"] for sent in thursday_doc.sents]\n",
    "\n",
    "print(len(emma_sents))\n",
    "print(len(persuasion_sents))\n",
    "print(len(brown_sents))\n",
    "print(len(thursday_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "#For computational purposes, reduce length of each set of sentences to 500\n",
    "emma_sents = emma_sents[0:500]\n",
    "persuasion_sents = persuasion_sents[0:500]\n",
    "brown_sents = brown_sents[0:500]\n",
    "thursday_sents = thursday_sents[0:500]\n",
    "\n",
    "print(len(emma_sents))\n",
    "print(len(persuasion_sents))\n",
    "print(len(brown_sents))\n",
    "print(len(thursday_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Emma, Woodhouse, ,, handsome, ,, clever, ,, a...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(She, was, the, youngest, of, the, two, daught...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Her, mother, had, died, too, long, ago, for, ...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Sixteen, years, had, Miss, Taylor, been, in, ...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Between, _, them)</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1\n",
       "0  (Emma, Woodhouse, ,, handsome, ,, clever, ,, a...  Austen\n",
       "1  (She, was, the, youngest, of, the, two, daught...  Austen\n",
       "2  (Her, mother, had, died, too, long, ago, for, ...  Austen\n",
       "3  (Sixteen, years, had, Miss, Taylor, been, in, ...  Austen\n",
       "4                                 (Between, _, them)  Austen"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Austen' 'Chesterton']\n"
     ]
    }
   ],
   "source": [
    "# Combine the sentences from the four texts into one data frame.\n",
    "sentences = pd.DataFrame(emma_sents + persuasion_sents + brown_sents + thursday_sents)\n",
    "\n",
    "#Confirm this worked\n",
    "display(sentences.head(5))\n",
    "\n",
    "#Confirm we only have two authors across four texts\n",
    "print(sentences.iloc[:, 1].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataFrame with BoW and TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 1000 most common words\n",
    "\n",
    "def bag_of_words(text):\n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "        \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Create column headers for sentence text and source (author) and initialize to 0\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the bags for each text\n",
    "emmawords = bag_of_words(emma_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "brownwords = bag_of_words(brown_doc)\n",
    "thursdaywords = bag_of_words(thursday_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(emmawords + persuasionwords + brownwords + thursdaywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create BoW Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assistance</th>\n",
       "      <th>somewhat</th>\n",
       "      <th>favourite</th>\n",
       "      <th>thorough</th>\n",
       "      <th>goddard</th>\n",
       "      <th>pleasing</th>\n",
       "      <th>steam</th>\n",
       "      <th>series</th>\n",
       "      <th>shirley</th>\n",
       "      <th>conversation</th>\n",
       "      <th>...</th>\n",
       "      <th>attachment</th>\n",
       "      <th>acknowledge</th>\n",
       "      <th>convey</th>\n",
       "      <th>heaven</th>\n",
       "      <th>walter</th>\n",
       "      <th>instead</th>\n",
       "      <th>daylight</th>\n",
       "      <th>tenderness</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Emma, Woodhouse, ,, handsome, ,, clever, ,, a...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(She, was, the, youngest, of, the, two, daught...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Her, mother, had, died, too, long, ago, for, ...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Sixteen, years, had, Miss, Taylor, been, in, ...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Between, _, them)</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(_)</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(it, was, more, the, intimacy, of, sisters, .)</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Even, before, Miss, Taylor, had, ceased, to, ...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, real, evils, ,, indeed, ,, of, Emma, 's,...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, danger, ,, however, ,, was, at, present,...</td>\n",
       "      <td>Austen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2035 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  assistance somewhat favourite thorough goddard pleasing steam series  \\\n",
       "0          0        0         0        0       0        0     0      0   \n",
       "1          0        0         0        0       0        0     0      0   \n",
       "2          0        0         0        0       0        0     0      0   \n",
       "3          0        0         0        0       0        0     0      0   \n",
       "4          0        0         0        0       0        0     0      0   \n",
       "5          0        0         0        0       0        0     0      0   \n",
       "6          0        0         0        0       0        0     0      0   \n",
       "7          0        0         0        0       0        0     0      0   \n",
       "8          0        0         0        0       0        0     0      0   \n",
       "9          0        0         0        0       0        0     0      0   \n",
       "\n",
       "  shirley conversation     ...     attachment acknowledge convey heaven  \\\n",
       "0       0            0     ...              0           0      0      0   \n",
       "1       0            0     ...              0           0      0      0   \n",
       "2       0            0     ...              0           0      0      0   \n",
       "3       0            0     ...              0           0      0      0   \n",
       "4       0            0     ...              0           0      0      0   \n",
       "5       0            0     ...              0           0      0      0   \n",
       "6       0            0     ...              0           0      0      0   \n",
       "7       0            0     ...              0           0      0      0   \n",
       "8       0            0     ...              0           0      0      0   \n",
       "9       0            0     ...              0           0      0      0   \n",
       "\n",
       "  walter instead daylight tenderness  \\\n",
       "0      0       0        0          0   \n",
       "1      0       0        0          0   \n",
       "2      0       0        0          0   \n",
       "3      0       0        0          0   \n",
       "4      0       0        0          0   \n",
       "5      0       0        0          0   \n",
       "6      0       0        0          0   \n",
       "7      0       0        0          0   \n",
       "8      0       0        0          0   \n",
       "9      0       0        0          0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Emma, Woodhouse, ,, handsome, ,, clever, ,, a...      Austen  \n",
       "1  (She, was, the, youngest, of, the, two, daught...      Austen  \n",
       "2  (Her, mother, had, died, too, long, ago, for, ...      Austen  \n",
       "3  (Sixteen, years, had, Miss, Taylor, been, in, ...      Austen  \n",
       "4                                 (Between, _, them)      Austen  \n",
       "5                                                (_)      Austen  \n",
       "6     (it, was, more, the, intimacy, of, sisters, .)      Austen  \n",
       "7  (Even, before, Miss, Taylor, had, ceased, to, ...      Austen  \n",
       "8  (The, real, evils, ,, indeed, ,, of, Emma, 's,...      Austen  \n",
       "9  (The, danger, ,, however, ,, was, at, present,...      Austen  \n",
       "\n",
       "[10 rows x 2035 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting Parts of Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of Words in Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create vectorizer model in order to get tf-idf for each sentence\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer -- will be done to source_text column in our dataframe since we already parsed sentences\n",
    "emma_paras_tfidf=vectorizer.fit_transform(emma_paras)\n",
    "print(emma_paras_tfidf)\n",
    "print(emma_paras_tfidf.shape)\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(emma_paras_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "#List of features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
